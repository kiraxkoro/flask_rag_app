ğŸ“š Flask RAG Server

A lightweight Retrieval-Augmented Generation (RAG) server built with Flask and LangChain, containerized with Docker for easy deployment.

ğŸš€ Features

Upload and index documents (PDFs, text files, etc.)

Query the documents using LLMs (OpenAI / Google GenAI)

Switch backend models via API

Run fully containerized with Docker

ğŸ› ï¸ Tech Stack

Flask (Python web framework)

LangChain Core & Community

LangChain OpenAI & Google GenAI integrations

Docker (for deployment)

ğŸ“‚ Project Structure
flask_rag_app/
â”‚â”€â”€ app.py              # Flask entrypoint
â”‚â”€â”€ requirements.txt    # Dependencies
â”‚â”€â”€ Dockerfile          # Docker build file
â”‚â”€â”€ data/               # Store uploaded documents
â”‚â”€â”€ README.md           # Project documentation


âš™ï¸ Installation
1ï¸âƒ£ Clone the repo
git clone https://github.com/your-username/flask-rag-server.git
cd flask-rag-server/flask_rag_app

2ï¸âƒ£ Build Docker image
docker build -t rag-app .

3ï¸âƒ£ Run the container
docker run -p 5000:5000 rag-app


Server runs at:
ğŸ‘‰ http://localhost:5000

ğŸ“¡ API Endpoints
ğŸ”¹ Upload documents
POST /upload

ğŸ”¹ Query documents
POST /query

ğŸ”¹ Switch backend model
POST /switch_model

ğŸ“¦ Dependencies

Your requirements.txt includes:

flask
langchain-core==0.3.75
langchain-community==0.3.29
langchain-openai==0.3.32
langchain-google-genai==2.1.10

ğŸ›³ï¸ Deployment

To run on a different machine:

Copy the project folder

Run docker build -t rag-app .

Run docker run -p 5000:5000 rag-app

No extra setup needed ğŸš€
